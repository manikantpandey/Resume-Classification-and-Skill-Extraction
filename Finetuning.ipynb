{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from peft import get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n",
    "import torch\n",
    "from typing import List, Tuple\n",
    "import PyPDF2\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(csv_path: str, pdf_folder_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"Loaded CSV with {len(df)} rows\")\n",
    "    \n",
    "    def clean_html(html_text):\n",
    "        if pd.isna(html_text):\n",
    "            return \"\"\n",
    "        soup = BeautifulSoup(html_text, 'html.parser')\n",
    "        text = soup.get_text(separator=' ', strip=True)\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    def read_pdf(file_path):\n",
    "        try:\n",
    "            with open(file_path, 'rb') as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                return ' '.join(page.extract_text() or '' for page in pdf_reader.pages).strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading PDF {file_path}: {str(e)}\")\n",
    "            return \"\"\n",
    "    \n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    def process_text(text):\n",
    "        if pd.isna(text) or text == \"\":\n",
    "            return \"\"\n",
    "        doc = nlp(text[:1000000])  \n",
    "        \n",
    "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "        skills = [token.text for token in doc if token.pos_ == \"NOUN\" and token.is_alpha]\n",
    "        \n",
    "        return f\"Entities: {entities}\\nSkills: {skills}\\nOriginal: {text[:1000]}\"\n",
    "\n",
    "    print(\"Cleaning HTML content...\")\n",
    "    df['cleaned_resume_html'] = df['Resume_html'].apply(clean_html)\n",
    "\n",
    "    print(\"Reading PDF files...\")\n",
    "    tqdm.pandas()\n",
    "    df['pdf_content'] = df.apply(lambda row: read_pdf(os.path.join(pdf_folder_path, row['Category'], f\"{row['ID']}.pdf\")), axis=1)\n",
    "\n",
    "    print(\"Processing resume content...\")\n",
    "    df['processed_resume_html'] = df['cleaned_resume_html'].apply(process_text)\n",
    "    df['processed_pdf_content'] = df['pdf_content'].apply(process_text)\n",
    "\n",
    "    df['final_processed_resume'] = df.apply(lambda row: \n",
    "        f\"HTML Content:\\n{row['processed_resume_html']}\\n\\nPDF Content:\\n{row['processed_pdf_content']}\", axis=1)\n",
    "\n",
    "    print(\"Data preprocessing completed\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_model(df: pd.DataFrame, tokenizer: AutoTokenizer, max_length: int = 512) -> Dataset:\n",
    "    texts = [f\"[CATEGORY]{row['Category']}[RESUME]{row['final_processed_resume']}[END]\" for _, row in df.iterrows()]\n",
    "    \n",
    "    unique_categories = df['Category'].unique()\n",
    "    category_to_id = {category: idx for idx, category in enumerate(unique_categories)}\n",
    "    labels = [category_to_id[category] for category in df['Category']]\n",
    "    \n",
    "    encodings = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    encodings['labels'] = torch.tensor(labels)\n",
    "    return Dataset.from_dict(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CSV with 2484 rows\n",
      "Cleaning HTML content...\n",
      "Reading PDF files...\n",
      "Processing resume content...\n",
      "Data preprocessing completed\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the data\n",
    "csv_path = 'D:\\jarvis-calling-hiring-contest\\Resume\\Resume.csv'\n",
    "pdf_folder_path = 'D:\\jarvis-calling-hiring-contest\\data\\data'\n",
    "df = load_and_preprocess_data(csv_path, pdf_folder_path)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer and model\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Add special tokens\n",
    "special_tokens_dict = {'additional_special_tokens': ['[CATEGORY]', '[RESUME]', '[END]']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "# Get unique categories and create a mapping\n",
    "unique_categories = df['Category'].unique()\n",
    "category_to_id = {category: idx for idx, category in enumerate(unique_categories)}\n",
    "num_labels = len(category_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized: ['model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Set padding token ID\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Resize token embeddings\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Prepare the model for k-bit training\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LoRA to the model\n",
    "model = get_peft_model(model, peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "train_dataset = prepare_data_for_model(train_df, tokenizer)\n",
    "val_dataset = prepare_data_for_model(val_df, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training arguments\n",
    "output_dir = 'D:\\jarvis-calling-hiring-contest\\model'\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384eefba59d946c8a64d86c703b79efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9041, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.14}\n",
      "{'loss': 3.764, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.29}\n",
      "{'loss': 3.7157, 'learning_rate': 6e-06, 'epoch': 0.43}\n",
      "{'loss': 3.9128, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.57}\n",
      "{'loss': 3.9061, 'learning_rate': 1e-05, 'epoch': 0.71}\n",
      "{'loss': 3.7967, 'learning_rate': 1.2e-05, 'epoch': 0.86}\n",
      "{'loss': 3.8565, 'learning_rate': 1.4000000000000001e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5698e689e51d4a718ae13bcfe43fa8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.9586000442504883, 'eval_accuracy': 0.028112449799196786, 'eval_precision': 0.024881984076657503, 'eval_recall': 0.028112449799196786, 'eval_f1': 0.025655090329542614, 'eval_runtime': 23.8896, 'eval_samples_per_second': 10.423, 'eval_steps_per_second': 1.339, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\peft\\utils\\save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\torch\\utils\\checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6572, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.14}\n",
      "{'loss': 3.667, 'learning_rate': 1.8e-05, 'epoch': 1.29}\n",
      "{'loss': 3.6336, 'learning_rate': 2e-05, 'epoch': 1.43}\n",
      "{'loss': 3.4715, 'learning_rate': 2.2000000000000003e-05, 'epoch': 1.57}\n",
      "{'loss': 3.5103, 'learning_rate': 2.4e-05, 'epoch': 1.71}\n",
      "{'loss': 3.4565, 'learning_rate': 2.6000000000000002e-05, 'epoch': 1.86}\n",
      "{'loss': 3.3718, 'learning_rate': 2.8000000000000003e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfa428ef0c64d3590cce05d6f77cb9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.6096770763397217, 'eval_accuracy': 0.03614457831325301, 'eval_precision': 0.049324749980313415, 'eval_recall': 0.03614457831325301, 'eval_f1': 0.036434083656566474, 'eval_runtime': 23.9212, 'eval_samples_per_second': 10.409, 'eval_steps_per_second': 1.338, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\peft\\utils\\save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\torch\\utils\\checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3645, 'learning_rate': 3e-05, 'epoch': 2.14}\n",
      "{'loss': 3.1565, 'learning_rate': 3.2000000000000005e-05, 'epoch': 2.29}\n",
      "{'loss': 3.0123, 'learning_rate': 3.4000000000000007e-05, 'epoch': 2.43}\n",
      "{'loss': 2.8555, 'learning_rate': 3.6e-05, 'epoch': 2.57}\n",
      "{'loss': 2.5164, 'learning_rate': 3.7800000000000004e-05, 'epoch': 2.71}\n",
      "{'loss': 1.6242, 'learning_rate': 3.9800000000000005e-05, 'epoch': 2.86}\n",
      "{'loss': 0.6437, 'learning_rate': 4.18e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ded5a3780b5446bad498819a9e22966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.55534553527832, 'eval_accuracy': 0.04417670682730924, 'eval_precision': 0.04417670682730924, 'eval_recall': 0.04417670682730924, 'eval_f1': 0.04417670682730924, 'eval_runtime': 24.13, 'eval_samples_per_second': 10.319, 'eval_steps_per_second': 1.326, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\peft\\utils\\save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\torch\\utils\\checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1421, 'learning_rate': 4.38e-05, 'epoch': 3.14}\n",
      "{'loss': 0.0296, 'learning_rate': 4.5600000000000004e-05, 'epoch': 3.29}\n",
      "{'loss': 0.0039, 'learning_rate': 4.76e-05, 'epoch': 3.43}\n",
      "{'loss': 0.0013, 'learning_rate': 4.96e-05, 'epoch': 3.57}\n",
      "{'loss': 0.0006, 'learning_rate': 5.16e-05, 'epoch': 3.71}\n",
      "{'loss': 0.0004, 'learning_rate': 5.360000000000001e-05, 'epoch': 3.86}\n",
      "{'loss': 0.0003, 'learning_rate': 5.560000000000001e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcdeec4c914a4a26913650fd4c229bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 12.213642120361328, 'eval_accuracy': 0.04417670682730924, 'eval_precision': 0.04417670682730924, 'eval_recall': 0.04417670682730924, 'eval_f1': 0.04417670682730924, 'eval_runtime': 23.8793, 'eval_samples_per_second': 10.427, 'eval_steps_per_second': 1.34, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\peft\\utils\\save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 4080.8188, 'train_samples_per_second': 2.191, 'train_steps_per_second': 0.069, 'train_loss': 2.4633959026383567, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=280, training_loss=2.4633959026383567, metrics={'train_runtime': 4080.8188, 'train_samples_per_second': 2.191, 'train_steps_per_second': 0.069, 'train_loss': 2.4633959026383567, 'epoch': 4.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63617b9998f492ca8accbaabb75862a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 3.6096770763397217, 'eval_accuracy': 0.03614457831325301, 'eval_precision': 0.049324749980313415, 'eval_recall': 0.03614457831325301, 'eval_f1': 0.036434083656566474, 'eval_runtime': 23.9401, 'eval_samples_per_second': 10.401, 'eval_steps_per_second': 1.337, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation results:\", eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\manik\\miniconda3\\lib\\site-packages\\peft\\utils\\save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning completed and Model saved.\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(\"Fine-tuning completed and Model saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
